{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjrzLvCplyMptDBv69FJmh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shimasaberianpour1375-gif/clinical-ml-outcomes-analysis/blob/main/models\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os2L3dEWprpU"
      },
      "outputs": [],
      "source": [
        "# --- Model 1: Logistic Regression ---\n",
        "print(\"\\n--- Model 1: Training Logistic Regression ---\")\n",
        "log_reg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "log_reg_model.fit(X_train_processed, y_train)\n",
        "y_pred_lr = log_reg_model.predict(X_test_processed)\n",
        "y_prob_lr = log_reg_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr, zero_division=0)\n",
        "recall_lr = recall_score(y_test, y_pred_lr, zero_division=0)\n",
        "f1_lr = f1_score(y_test, y_pred_lr, zero_division=0)\n",
        "auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
        "\n",
        "results['Logistic Regression'] = {\n",
        "    'Accuracy': accuracy_lr, 'Precision': precision_lr, 'Recall': recall_lr,\n",
        "    'F1-Score': f1_lr, 'AUC-ROC': auc_lr\n",
        "}\n",
        "models['Logistic Regression'] = log_reg_model\n",
        "print(\"Logistic Regression trained and evaluated.\")\n",
        "\n",
        "# --- Model 2: Random Forest Classifier ---\n",
        "print(\"\\n--- Model 2: Training Random Forest Classifier ---\")\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train_processed, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_processed)\n",
        "y_prob_rf = rf_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf, zero_division=0)\n",
        "recall_rf = recall_score(y_test, y_pred_rf, zero_division=0)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, zero_division=0)\n",
        "auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
        "\n",
        "results['Random Forest'] = {\n",
        "    'Accuracy': accuracy_rf, 'Precision': precision_rf, 'Recall': recall_rf,\n",
        "    'F1-Score': f1_rf, 'AUC-ROC': auc_rf\n",
        "}\n",
        "models['Random Forest'] = rf_model\n",
        "print(\"Random Forest trained and evaluated.\")\n",
        "\n",
        "# --- Model 3: XGBoost Classifier ---\n",
        "print(\"\\n--- Model 3: Training XGBoost Classifier ---\")\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train_processed, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
        "y_prob_xgb = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb = precision_score(y_test, y_pred_xgb, zero_division=0)\n",
        "recall_xgb = recall_score(y_test, y_pred_xgb, zero_division=0)\n",
        "f1_xgb = f1_score(y_test, y_pred_xgb, zero_division=0)\n",
        "auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
        "\n",
        "results['XGBoost'] = {\n",
        "    'Accuracy': accuracy_xgb, 'Precision': precision_xgb, 'Recall': recall_xgb,\n",
        "    'F1-Score': f1_xgb, 'AUC-ROC': auc_xgb\n",
        "}\n",
        "models['XGBoost'] = xgb_model\n",
        "print(\"XGBoost trained and evaluated.\")\n",
        "\n",
        "# --- Model 4: Support Vector Machine (SVM) ---\n",
        "print(\"\\n--- Model 4: Training Support Vector Machine (SVM) ---\")\n",
        "svm_model = SVC(random_state=42, probability=True, C=1.0, kernel='rbf')\n",
        "svm_model.fit(X_train_processed, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_processed)\n",
        "y_prob_svm = svm_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, zero_division=0)\n",
        "recall_svm = recall_score(y_test, y_pred_svm, zero_division=0)\n",
        "f1_svm = f1_score(y_test, y_pred_svm, zero_division=0)\n",
        "auc_svm = roc_auc_score(y_test, y_prob_svm)\n",
        "\n",
        "results['SVM'] = {\n",
        "    'Accuracy': accuracy_svm, 'Precision': precision_svm, 'Recall': recall_svm,\n",
        "    'F1-Score': f1_svm, 'AUC-ROC': auc_svm\n",
        "}\n",
        "models['SVM'] = svm_model\n",
        "print(\"SVM trained and evaluated.\")\n",
        "\n",
        "# --- Model 5: Neural Network (MLPClassifier) ---\n",
        "print(\"\\n--- Model 5: Training Neural Network (MLPClassifier) ---\")\n",
        "mlp_model = MLPClassifier(random_state=42, hidden_layer_sizes=(100,), max_iter=500, activation='relu', solver='adam')\n",
        "mlp_model.fit(X_train_processed, y_train)\n",
        "y_pred_mlp = mlp_model.predict(X_test_processed)\n",
        "y_prob_mlp = mlp_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp, zero_division=0)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp, zero_division=0)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp, zero_division=0)\n",
        "auc_mlp = roc_auc_score(y_test, y_prob_mlp)\n",
        "\n",
        "results['Neural Network (MLP)'] = {\n",
        "    'Accuracy': accuracy_mlp, 'Precision': precision_mlp, 'Recall': recall_mlp,\n",
        "    'F1-Score': f1_mlp, 'AUC-ROC': auc_mlp\n",
        "}\n",
        "models['Neural Network (MLP)'] = mlp_model\n",
        "print(\"Neural Network (MLPClassifier) trained and evaluated.\")\n",
        "\n",
        "# --- Model 6: K-Nearest Neighbors (KNN) ---\n",
        "print(\"\\n--- Model 6: Training K-Nearest Neighbors (KNN) ---\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_processed, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test_processed)\n",
        "y_prob_knn = knn_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn, zero_division=0)\n",
        "recall_knn = recall_score(y_test, y_pred_knn, zero_division=0)\n",
        "f1_knn = f1_score(y_test, y_pred_knn, zero_division=0)\n",
        "auc_knn = roc_auc_score(y_test, y_prob_knn)\n",
        "\n",
        "results['KNN'] = {\n",
        "    'Accuracy': accuracy_knn, 'Precision': precision_knn, 'Recall': recall_knn,\n",
        "    'F1-Score': f1_knn, 'AUC-ROC': auc_knn\n",
        "}\n",
        "models['KNN'] = knn_model\n",
        "print(\"K-Nearest Neighbors trained and evaluated.\")\n",
        "\n",
        "# --- Model 7: Gaussian Naive Bayes ---\n",
        "print(\"\\n--- Model 7: Training Gaussian Naive Bayes ---\")\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train_processed, y_train)\n",
        "y_pred_gnb = gnb_model.predict(X_test_processed)\n",
        "y_prob_gnb = gnb_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "precision_gnb = precision_score(y_test, y_pred_gnb, zero_division=0)\n",
        "recall_gnb = recall_score(y_test, y_pred_gnb, zero_division=0)\n",
        "f1_gnb = f1_score(y_test, y_pred_gnb, zero_division=0)\n",
        "auc_gnb = roc_auc_score(y_test, y_prob_gnb)\n",
        "\n",
        "results['Naive Bayes'] = {\n",
        "    'Accuracy': accuracy_gnb, 'Precision': precision_gnb, 'Recall': recall_gnb,\n",
        "    'F1-Score': f1_gnb, 'AUC-ROC': auc_gnb\n",
        "}\n",
        "models['Naive Bayes'] = gnb_model\n",
        "print(\"Gaussian Naive Bayes trained and evaluated.\")\n",
        "\n",
        "# --- Model 8: Voting Classifier ---\n",
        "print(\"\\n--- Model 8: Training Voting Classifier ---\")\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg_model),\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('svm', svm_model),\n",
        "        ('mlp', mlp_model),\n",
        "        ('knn', knn_model),\n",
        "        ('gnb', gnb_model)\n",
        "    ],\n",
        "    voting='soft',\n",
        "\n",
        ")\n",
        "voting_clf.fit(X_train_processed, y_train)\n",
        "y_pred_voting = voting_clf.predict(X_test_processed)\n",
        "y_prob_voting = voting_clf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
        "precision_voting = precision_score(y_test, y_pred_voting, zero_division=0)\n",
        "recall_voting = recall_score(y_test, y_pred_voting, zero_division=0)\n",
        "f1_voting = f1_score(y_test, y_pred_voting, zero_division=0)\n",
        "auc_voting = roc_auc_score(y_test, y_prob_voting)\n",
        "\n",
        "results['Voting Classifier'] = {\n",
        "    'Accuracy': accuracy_voting, 'Precision': precision_voting, 'Recall': recall_voting,\n",
        "    'F1-Score': f1_voting, 'AUC-ROC': auc_voting\n",
        "}\n",
        "models['Voting Classifier'] = voting_clf\n",
        "print(\"Voting Classifier trained and evaluated.\")\n",
        "\n",
        "# --- Hyperparameter Tuning Example (Random Forest) ---\n",
        "print(\"\\n--- Hyperparameter Tuning Example (Random Forest) ---\")\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid_rf,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    verbose=0,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "print(\"Starting Grid Search for Random Forest....\")\n",
        "grid_search_rf.fit(X_train_processed, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
        "print(f\"Best cross-validated AUC-ROC for Random Forest: {grid_search_rf.best_score_:.3f}\")\n",
        "\n",
        "tuned_rf_model = grid_search_rf.best_estimator_\n",
        "y_pred_tuned_rf = tuned_rf_model.predict(X_test_processed)\n",
        "y_prob_tuned_rf = tuned_rf_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "tuned_accuracy_rf = accuracy_score(y_test, y_pred_tuned_rf)\n",
        "tuned_precision_rf = precision_score(y_test, y_pred_tuned_rf, zero_division=0)\n",
        "tuned_recall_rf = recall_score(y_test, y_pred_tuned_rf, zero_division=0)\n",
        "tuned_f1_rf = f1_score(y_test, y_pred_tuned_rf, zero_division=0)\n",
        "tuned_auc_rf = roc_auc_score(y_test, y_prob_tuned_rf)\n",
        "\n",
        "results['Tuned Random Forest'] = {\n",
        "    'Accuracy': tuned_accuracy_rf, 'Precision': tuned_precision_rf, 'Recall': tuned_recall_rf,\n",
        "    'F1-Score': tuned_f1_rf, 'AUC-ROC': tuned_auc_rf\n",
        "}\n",
        "models['Tuned Random Forest'] = tuned_rf_model\n",
        "print(\"Tuned Random Forest evaluated on test set.\")\n",
        "print(pd.DataFrame([results['Tuned Random Forest']], index=['Tuned Random Forest']).round(3))\n",
        "\n",
        "# --- Hyperparameter Tuning for XGBoost ---\n",
        "print(\"\\n--- Hyperparameter Tuning for XGBoost ---\")\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'subsample': [0.7, 1.0],\n",
        "    'colsample_bytree': [0.7, 1.0]\n",
        "}\n",
        "\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    estimator=xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
        "    param_grid=param_grid_xgb,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    verbose=0,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "print(\"Starting Grid Search for XGBoost....\")\n",
        "grid_search_xgb.fit(X_train_processed, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for XGBoost: {grid_search_xgb.best_params_}\")\n",
        "print(f\"Best cross-validated AUC-ROC for XGBoost: {grid_search_xgb.best_score_:.3f}\")\n",
        "\n",
        "tuned_xgb_model = grid_search_xgb.best_estimator_\n",
        "y_pred_tuned_xgb = tuned_xgb_model.predict(X_test_processed)\n",
        "y_prob_tuned_xgb = tuned_xgb_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "tuned_accuracy_xgb = accuracy_score(y_test, y_pred_tuned_xgb)\n",
        "tuned_precision_xgb = precision_score(y_test, y_pred_tuned_xgb, zero_division=0)\n",
        "tuned_recall_xgb = recall_score(y_test, y_pred_tuned_xgb, zero_division=0)\n",
        "tuned_f1_xgb = f1_score(y_test, y_pred_tuned_xgb, zero_division=0)\n",
        "tuned_auc_xgb = roc_auc_score(y_test, y_prob_tuned_xgb)\n",
        "\n",
        "results['Tuned XGBoost'] = {\n",
        "    'Accuracy': tuned_accuracy_xgb, 'Precision': tuned_precision_xgb, 'Recall': tuned_recall_xgb,\n",
        "    'F1-Score': tuned_f1_xgb, 'AUC-ROC': tuned_auc_xgb\n",
        "}\n",
        "models['Tuned XGBoost'] = tuned_xgb_model\n",
        "print(\"Tuned XGBoost evaluated on test set.\")\n",
        "print(pd.DataFrame([results['Tuned XGBoost']], index=['Tuned XGBoost']).round(3))\n",
        "\n",
        "# --- Handling Class Imbalance with SMOTE  (Random Forest) ---\n",
        "print(\"\\n--- Handling Class Imbalance with SMOTE  (Random Forest) ---\")\n",
        "\n",
        "pipeline_smote_rf = ImbPipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
        "])\n",
        "\n",
        "print(\"Training Random Forest with SMOTE ...\")\n",
        "pipeline_smote_rf.fit(X_train_processed, y_train)\n",
        "y_pred_smote_rf = pipeline_smote_rf.predict(X_test_processed)\n",
        "y_prob_smote_rf = pipeline_smote_rf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "smote_accuracy_rf = accuracy_score(y_test, y_pred_smote_rf)\n",
        "smote_precision_rf = precision_score(y_test, y_pred_smote_rf, zero_division=0)\n",
        "smote_recall_rf = recall_score(y_test, y_pred_smote_rf, zero_division=0)\n",
        "smote_f1_rf = f1_score(y_test, y_pred_smote_rf, zero_division=0)\n",
        "smote_auc_rf = roc_auc_score(y_test, y_prob_smote_rf)\n",
        "\n",
        "results['RF + SMOTE'] = {\n",
        "    'Accuracy': smote_accuracy_rf, 'Precision': smote_precision_rf, 'Recall': smote_recall_rf,\n",
        "    'F1-Score': smote_f1_rf, 'AUC-ROC': smote_auc_rf\n",
        "}\n",
        "models['RF + SMOTE'] = pipeline_smote_rf\n",
        "print(\"Random Forest with SMOTE evaluated on test set.\")\n",
        "print(pd.DataFrame([results['RF + SMOTE']], index=['RF + SMOTE']).round(3))\n",
        "\n",
        "\n",
        "\n",
        "# --- Deep Learning Model with Keras ---\n",
        "print(\"\\n--- Deep Learning Model with Keras ---\")\n",
        "\n",
        "def create_keras_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "    return model\n",
        "\n",
        "input_dim = X_train_processed.shape[1]\n",
        "keras_model = create_keras_model(input_dim)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"Training Keras Deep Learning Model. This will show training progress...\")\n",
        "history = keras_model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=0\n",
        ")\n",
        "print(\"Keras Deep Learning Model training complete.\")\n",
        "\n",
        "loss, accuracy_keras, auc_keras = keras_model.evaluate(X_test_processed, y_test, verbose=0)\n",
        "y_prob_keras = keras_model.predict(X_test_processed).flatten()\n",
        "y_pred_keras = (y_prob_keras > 0.5).astype(int)\n",
        "\n",
        "precision_keras = precision_score(y_test, y_pred_keras, zero_division=0)\n",
        "recall_keras = recall_score(y_test, y_pred_keras, zero_division=0)\n",
        "f1_keras = f1_score(y_test, y_pred_keras, zero_division=0)\n",
        "\n",
        "results['Deep Learning (Keras)'] = {\n",
        "    'Accuracy': accuracy_keras, 'Precision': precision_keras, 'Recall': recall_keras,\n",
        "    'F1-Score': f1_keras, 'AUC-ROC': auc_keras\n",
        "}\n",
        "models['Deep Learning (Keras)'] = keras_model\n",
        "print(\"Deep Learning (Keras) evaluated on test set.\")\n",
        "print(pd.DataFrame([results['Deep Learning (Keras)']], index=['Deep Learning (Keras)']).round(3))\n",
        "\n",
        "# --- Stacking Classifier ---\n",
        "print(\"\\n--- Stacking Classifier ---\")\n",
        "\n",
        "estimators = [\n",
        "    ('lr', models['Logistic Regression']),\n",
        "    ('tuned_rf', models['Tuned Random Forest']),\n",
        "    ('tuned_xgb', models['Tuned XGBoost']),\n",
        "    ('mlp', models['Neural Network (MLP)'])\n",
        "]\n",
        "\n",
        "stk_meta_classifier = LogisticRegression(random_state=42, solver='liblinear')\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=stk_meta_classifier,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "print(\"Training Stacking Classifier. ..\")\n",
        "stacking_clf.fit(X_train_processed, y_train)\n",
        "y_pred_stk = stacking_clf.predict(X_test_processed)\n",
        "y_prob_stk = stacking_clf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_stk = accuracy_score(y_test, y_pred_stk)\n",
        "precision_stk = precision_score(y_test, y_pred_stk, zero_division=0)\n",
        "recall_stk = recall_score(y_test, y_pred_stk, zero_division=0)\n",
        "f1_stk = f1_score(y_test, y_pred_stk, zero_division=0)\n",
        "auc_stk = roc_auc_score(y_test, y_prob_stk)\n",
        "\n",
        "results['Stacking Classifier'] = {\n",
        "    'Accuracy': accuracy_stk, 'Precision': precision_stk, 'Recall': recall_stk,\n",
        "    'F1-Score': f1_stk, 'AUC-ROC': auc_stk\n",
        "}\n",
        "models['Stacking Classifier'] = stacking_clf\n",
        "print(\"Stacking Classifier trained and evaluated.\")\n",
        "print(pd.DataFrame([results['Stacking Classifier']], index=['Stacking Classifier']).round(3))\n"
      ]
    }
  ]
}