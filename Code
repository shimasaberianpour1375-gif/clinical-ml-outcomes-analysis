{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPse6t8zOZXCZOn8+SjXTk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shimasaberianpour1375-gif/clinical-ml-outcomes-analysis/blob/main/Code\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYcAuVxtdDqI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For handling imbalance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "\n",
        "# For Deep Learning (Keras with TensorFlow backend)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# For SHAP\n",
        "import shap\n",
        "\n",
        "# --- Configuration ---\n",
        "DATA_PATH = 'physio.csv'\n",
        "TARGET_VARIABLE = 'pain'\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Load the Dataset ---\n",
        "print(\"--- Step 1: Loading Dataset ---\")\n",
        "try:\n",
        "    df = pd.read_csv(DATA_PATH)\n",
        "    print(f\"Dataset loaded successfully from {DATA_PATH}.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {DATA_PATH} not found\")\n",
        "    exit()\n",
        "\n",
        "# --- Step 2: Initial Data Inspection\n",
        "\n",
        "# all columns to be used initially before dropping anything\n",
        "all_data_columns = df.columns.tolist()\n",
        "\n",
        "numerical_cols_for_imputation = df.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols_for_imputation = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# The target variable should not be imputed with features data\n",
        "if TARGET_VARIABLE in numerical_cols_for_imputation:\n",
        "    numerical_cols_for_imputation.remove(TARGET_VARIABLE)\n",
        "if TARGET_VARIABLE in categorical_cols_for_imputation:\n",
        "    categorical_cols_for_imputation.remove(TARGET_VARIABLE)\n",
        "\n",
        "# **********Handle missing values for numerical and categorical columns\n",
        "for col in numerical_cols_for_imputation:\n",
        "    if df[col].isnull().any():\n",
        "        median_val = df[col].median()\n",
        "        df[col].fillna(median_val, inplace=True)\n",
        "        print(f\"Imputed missing values in '{col}' with median: {median_val}\")\n",
        "\n",
        "for col in categorical_cols_for_imputation:\n",
        "    if df[col].isnull().any():\n",
        "        mode_val = df[col].mode()[0]\n",
        "        df[col].fillna(mode_val, inplace=True)\n",
        "        print(f\"Imputed missing values in '{col}' with mode: {mode_val}\")\n",
        "\n",
        "# --- Step 3: Define Features (X) and Target (y)\n",
        "print(\"\\n--- Step 3: Defining Features (X) and Target (y)  ---\")\n",
        "\n",
        "#  independent variables for 'pain' target\n",
        "selected_independent_variables = [\n",
        "    'gender', 'age', 'symptoms', 'treatments', 'episodes', 'baseline'\n",
        "]\n",
        "\n",
        "# ******* columns exist in the DataFrame before selecting\n",
        "missing_cols = [col for col in selected_independent_variables if col not in df.columns]\n",
        "if missing_cols:\n",
        "    print(f\"Error: variables are not found in the dataset: {missing_cols}\")\n",
        "    exit()\n",
        "\n",
        "X = df[selected_independent_variables]\n",
        "y = df[TARGET_VARIABLE]\n",
        "\n",
        "print(f\"\\nFeatures (X) shape with selected independent variables: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "\n",
        "# --- Step 4: Separate Feature Types for Preprocessing\n",
        "print(\"\\n--- Step 4: Separating Feature Types for Preprocessing ---\")\n",
        "\n",
        "# Updated lists for numerical and categorical features\n",
        "numerical_features = ['age']\n",
        "categorical_features = ['gender', 'symptoms', 'treatments', 'episodes', 'baseline']\n",
        "\n",
        "# *******************************Verify that all selected columns in X are accounted\n",
        "all_processed_features = set(numerical_features + categorical_features)\n",
        "X_columns_set = set(X.columns.tolist())\n",
        "\n",
        "if all_processed_features != X_columns_set:\n",
        "    print(\"\\n--- WARNING: Mismatch in selected feature lists ---\")\n",
        "    print(f\"Columns in X but not in feature lists: {X_columns_set - all_processed_features}\")\n",
        "    print(f\"Features listed but not in X: {all_processed_features - X_columns_set}\")\n",
        "    print(\"Please double-check the numerical/categorical lists against your explicitly selected X columns.\")\n",
        "else:\n",
        "    print(f\"\\nNumerical Features identified: {numerical_features}\")\n",
        "    print(f\"Categorical Features identified: {categorical_features}\")\n",
        "\n",
        "# --- Step 5:Preprocessing Pipeline ---\n",
        "print(\"\\n--- Step 5: Preprocessing Pipeline ---\")\n",
        "\n",
        "numerical_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
        "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(drop=\"first\",handle_unknown='ignore'))])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "print(\"Preprocessing pipeline created.\")\n",
        "\n",
        "# --- Step 6: Split Data into Training and Testing Sets ---\n",
        "print(\"\\n--- Step 6: Splitting data into Training and Testing sets ---\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# --- Step 7: Apply Preprocessing to Training and Testing Sets ---\n",
        "print(\"\\n--- Step 7: Applying Preprocessing to Training and Testing Sets ---\")\n",
        "# Original: X_train_processed = preprocessor.fit_transform(X_train)\n",
        "# Original: X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# MODIFIED: Convert to dense arrays immediately after preprocessing\n",
        "X_train_processed = preprocessor.fit_transform(X_train).toarray() # Add .toarray()\n",
        "X_test_processed = preprocessor.transform(X_test).toarray()     # Add .toarray()\n",
        "\n",
        "try:\n",
        "    ohe_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_features)\n",
        "    processed_feature_names = numerical_features + list(ohe_feature_names)\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not retrieve feature names after one-hot encoding: {e}. Using generic names.\")\n",
        "    processed_feature_names = [f'feature_{i}' for i in range(X_train_processed.shape[1])]\n",
        "\n",
        "print(f\"X_train_processed shape: {X_train_processed.shape}\")\n",
        "print(f\"X_test_processed shape: {X_test_processed.shape}\")\n",
        "\n",
        "print(\"\\n--- Pre-ML Steps Complete and Data Ready for Modeling ---\")\n",
        "results = {}\n",
        "models = {}\n"
      ],
      "metadata": {
        "id": "Vnart6kJeX4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "A9YwRq1EfT0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Model 1: Logistic Regression ---\n",
        "print(\"\\n--- Model 1: Training Logistic Regression ---\")\n",
        "log_reg_model = LogisticRegression(random_state=42, solver='liblinear', max_iter=1000)\n",
        "log_reg_model.fit(X_train_processed, y_train)\n",
        "y_pred_lr = log_reg_model.predict(X_test_processed)\n",
        "y_prob_lr = log_reg_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr, zero_division=0)\n",
        "recall_lr = recall_score(y_test, y_pred_lr, zero_division=0)\n",
        "f1_lr = f1_score(y_test, y_pred_lr, zero_division=0)\n",
        "auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
        "\n",
        "results['Logistic Regression'] = {\n",
        "    'Accuracy': accuracy_lr, 'Precision': precision_lr, 'Recall': recall_lr,\n",
        "    'F1-Score': f1_lr, 'AUC-ROC': auc_lr\n",
        "}\n",
        "models['Logistic Regression'] = log_reg_model\n",
        "print(\"Logistic Regression trained and evaluated.\")\n",
        "\n",
        "# --- Model 2: Random Forest Classifier ---\n",
        "print(\"\\n--- Model 2: Training Random Forest Classifier ---\")\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train_processed, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test_processed)\n",
        "y_prob_rf = rf_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "precision_rf = precision_score(y_test, y_pred_rf, zero_division=0)\n",
        "recall_rf = recall_score(y_test, y_pred_rf, zero_division=0)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, zero_division=0)\n",
        "auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
        "\n",
        "results['Random Forest'] = {\n",
        "    'Accuracy': accuracy_rf, 'Precision': precision_rf, 'Recall': recall_rf,\n",
        "    'F1-Score': f1_rf, 'AUC-ROC': auc_rf\n",
        "}\n",
        "models['Random Forest'] = rf_model\n",
        "print(\"Random Forest trained and evaluated.\")\n",
        "\n",
        "# --- Model 3: XGBoost Classifier ---\n",
        "print(\"\\n--- Model 3: Training XGBoost Classifier ---\")\n",
        "xgb_model = xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_model.fit(X_train_processed, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test_processed)\n",
        "y_prob_xgb = xgb_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb = precision_score(y_test, y_pred_xgb, zero_division=0)\n",
        "recall_xgb = recall_score(y_test, y_pred_xgb, zero_division=0)\n",
        "f1_xgb = f1_score(y_test, y_pred_xgb, zero_division=0)\n",
        "auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
        "\n",
        "results['XGBoost'] = {\n",
        "    'Accuracy': accuracy_xgb, 'Precision': precision_xgb, 'Recall': recall_xgb,\n",
        "    'F1-Score': f1_xgb, 'AUC-ROC': auc_xgb\n",
        "}\n",
        "models['XGBoost'] = xgb_model\n",
        "print(\"XGBoost trained and evaluated.\")\n",
        "\n",
        "# --- Model 4: Support Vector Machine (SVM) ---\n",
        "print(\"\\n--- Model 4: Training Support Vector Machine (SVM) ---\")\n",
        "svm_model = SVC(random_state=42, probability=True, C=1.0, kernel='rbf')\n",
        "svm_model.fit(X_train_processed, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test_processed)\n",
        "y_prob_svm = svm_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm, zero_division=0)\n",
        "recall_svm = recall_score(y_test, y_pred_svm, zero_division=0)\n",
        "f1_svm = f1_score(y_test, y_pred_svm, zero_division=0)\n",
        "auc_svm = roc_auc_score(y_test, y_prob_svm)\n",
        "\n",
        "results['SVM'] = {\n",
        "    'Accuracy': accuracy_svm, 'Precision': precision_svm, 'Recall': recall_svm,\n",
        "    'F1-Score': f1_svm, 'AUC-ROC': auc_svm\n",
        "}\n",
        "models['SVM'] = svm_model\n",
        "print(\"SVM trained and evaluated.\")\n",
        "\n",
        "# --- Model 5: Neural Network (MLPClassifier) ---\n",
        "print(\"\\n--- Model 5: Training Neural Network (MLPClassifier) ---\")\n",
        "mlp_model = MLPClassifier(random_state=42, hidden_layer_sizes=(100,), max_iter=500, activation='relu', solver='adam')\n",
        "mlp_model.fit(X_train_processed, y_train)\n",
        "y_pred_mlp = mlp_model.predict(X_test_processed)\n",
        "y_prob_mlp = mlp_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "precision_mlp = precision_score(y_test, y_pred_mlp, zero_division=0)\n",
        "recall_mlp = recall_score(y_test, y_pred_mlp, zero_division=0)\n",
        "f1_mlp = f1_score(y_test, y_pred_mlp, zero_division=0)\n",
        "auc_mlp = roc_auc_score(y_test, y_prob_mlp)\n",
        "\n",
        "results['Neural Network (MLP)'] = {\n",
        "    'Accuracy': accuracy_mlp, 'Precision': precision_mlp, 'Recall': recall_mlp,\n",
        "    'F1-Score': f1_mlp, 'AUC-ROC': auc_mlp\n",
        "}\n",
        "models['Neural Network (MLP)'] = mlp_model\n",
        "print(\"Neural Network (MLPClassifier) trained and evaluated.\")\n",
        "\n",
        "# --- Model 6: K-Nearest Neighbors (KNN) ---\n",
        "print(\"\\n--- Model 6: Training K-Nearest Neighbors (KNN) ---\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_processed, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test_processed)\n",
        "y_prob_knn = knn_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn, zero_division=0)\n",
        "recall_knn = recall_score(y_test, y_pred_knn, zero_division=0)\n",
        "f1_knn = f1_score(y_test, y_pred_knn, zero_division=0)\n",
        "auc_knn = roc_auc_score(y_test, y_prob_knn)\n",
        "\n",
        "results['KNN'] = {\n",
        "    'Accuracy': accuracy_knn, 'Precision': precision_knn, 'Recall': recall_knn,\n",
        "    'F1-Score': f1_knn, 'AUC-ROC': auc_knn\n",
        "}\n",
        "models['KNN'] = knn_model\n",
        "print(\"K-Nearest Neighbors trained and evaluated.\")\n",
        "\n",
        "# --- Model 7: Gaussian Naive Bayes ---\n",
        "print(\"\\n--- Model 7: Training Gaussian Naive Bayes ---\")\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_train_processed, y_train)\n",
        "y_pred_gnb = gnb_model.predict(X_test_processed)\n",
        "y_prob_gnb = gnb_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "precision_gnb = precision_score(y_test, y_pred_gnb, zero_division=0)\n",
        "recall_gnb = recall_score(y_test, y_pred_gnb, zero_division=0)\n",
        "f1_gnb = f1_score(y_test, y_pred_gnb, zero_division=0)\n",
        "auc_gnb = roc_auc_score(y_test, y_prob_gnb)\n",
        "\n",
        "results['Naive Bayes'] = {\n",
        "    'Accuracy': accuracy_gnb, 'Precision': precision_gnb, 'Recall': recall_gnb,\n",
        "    'F1-Score': f1_gnb, 'AUC-ROC': auc_gnb\n",
        "}\n",
        "models['Naive Bayes'] = gnb_model\n",
        "print(\"Gaussian Naive Bayes trained and evaluated.\")\n",
        "\n",
        "# --- Model 8: Voting Classifier ---\n",
        "print(\"\\n--- Model 8: Training Voting Classifier ---\")\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', log_reg_model),\n",
        "        ('rf', rf_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('svm', svm_model),\n",
        "        ('mlp', mlp_model),\n",
        "        ('knn', knn_model),\n",
        "        ('gnb', gnb_model)\n",
        "    ],\n",
        "    voting='soft',\n",
        "\n",
        ")\n",
        "voting_clf.fit(X_train_processed, y_train)\n",
        "y_pred_voting = voting_clf.predict(X_test_processed)\n",
        "y_prob_voting = voting_clf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
        "precision_voting = precision_score(y_test, y_pred_voting, zero_division=0)\n",
        "recall_voting = recall_score(y_test, y_pred_voting, zero_division=0)\n",
        "f1_voting = f1_score(y_test, y_pred_voting, zero_division=0)\n",
        "auc_voting = roc_auc_score(y_test, y_prob_voting)\n",
        "\n",
        "results['Voting Classifier'] = {\n",
        "    'Accuracy': accuracy_voting, 'Precision': precision_voting, 'Recall': recall_voting,\n",
        "    'F1-Score': f1_voting, 'AUC-ROC': auc_voting\n",
        "}\n",
        "models['Voting Classifier'] = voting_clf\n",
        "print(\"Voting Classifier trained and evaluated.\")\n",
        "\n",
        "# --- Hyperparameter Tuning Example (Random Forest) ---\n",
        "print(\"\\n--- Hyperparameter Tuning Example (Random Forest) ---\")\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(\n",
        "    estimator=RandomForestClassifier(random_state=42),\n",
        "    param_grid=param_grid_rf,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    verbose=0,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "print(\"Starting Grid Search for Random Forest....\")\n",
        "grid_search_rf.fit(X_train_processed, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for Random Forest: {grid_search_rf.best_params_}\")\n",
        "print(f\"Best cross-validated AUC-ROC for Random Forest: {grid_search_rf.best_score_:.3f}\")\n",
        "\n",
        "tuned_rf_model = grid_search_rf.best_estimator_\n",
        "y_pred_tuned_rf = tuned_rf_model.predict(X_test_processed)\n",
        "y_prob_tuned_rf = tuned_rf_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "tuned_accuracy_rf = accuracy_score(y_test, y_pred_tuned_rf)\n",
        "tuned_precision_rf = precision_score(y_test, y_pred_tuned_rf, zero_division=0)\n",
        "tuned_recall_rf = recall_score(y_test, y_pred_tuned_rf, zero_division=0)\n",
        "tuned_f1_rf = f1_score(y_test, y_pred_tuned_rf, zero_division=0)\n",
        "tuned_auc_rf = roc_auc_score(y_test, y_prob_tuned_rf)\n",
        "\n",
        "results['Tuned Random Forest'] = {\n",
        "    'Accuracy': tuned_accuracy_rf, 'Precision': tuned_precision_rf, 'Recall': tuned_recall_rf,\n",
        "    'F1-Score': tuned_f1_rf, 'AUC-ROC': tuned_auc_rf\n",
        "}\n",
        "models['Tuned Random Forest'] = tuned_rf_model\n",
        "print(\"Tuned Random Forest evaluated on test set.\")\n",
        "print(pd.DataFrame([results['Tuned Random Forest']], index=['Tuned Random Forest']).round(3))\n",
        "\n",
        "# --- Hyperparameter Tuning for XGBoost ---\n",
        "print(\"\\n--- Hyperparameter Tuning for XGBoost ---\")\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 6, 9],\n",
        "    'learning_rate': [0.05, 0.1, 0.2],\n",
        "    'subsample': [0.7, 1.0],\n",
        "    'colsample_bytree': [0.7, 1.0]\n",
        "}\n",
        "\n",
        "grid_search_xgb = GridSearchCV(\n",
        "    estimator=xgb.XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
        "    param_grid=param_grid_xgb,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    verbose=0,\n",
        "    scoring='roc_auc'\n",
        ")\n",
        "\n",
        "print(\"Starting Grid Search for XGBoost....\")\n",
        "grid_search_xgb.fit(X_train_processed, y_train)\n",
        "\n",
        "print(f\"\\nBest parameters for XGBoost: {grid_search_xgb.best_params_}\")\n",
        "print(f\"Best cross-validated AUC-ROC for XGBoost: {grid_search_xgb.best_score_:.3f}\")\n",
        "\n",
        "tuned_xgb_model = grid_search_xgb.best_estimator_\n",
        "y_pred_tuned_xgb = tuned_xgb_model.predict(X_test_processed)\n",
        "y_prob_tuned_xgb = tuned_xgb_model.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "tuned_accuracy_xgb = accuracy_score(y_test, y_pred_tuned_xgb)\n",
        "tuned_precision_xgb = precision_score(y_test, y_pred_tuned_xgb, zero_division=0)\n",
        "tuned_recall_xgb = recall_score(y_test, y_pred_tuned_xgb, zero_division=0)\n",
        "tuned_f1_xgb = f1_score(y_test, y_pred_tuned_xgb, zero_division=0)\n",
        "tuned_auc_xgb = roc_auc_score(y_test, y_prob_tuned_xgb)\n",
        "\n",
        "results['Tuned XGBoost'] = {\n",
        "    'Accuracy': tuned_accuracy_xgb, 'Precision': tuned_precision_xgb, 'Recall': tuned_recall_xgb,\n",
        "    'F1-Score': tuned_f1_xgb, 'AUC-ROC': tuned_auc_xgb\n",
        "}\n",
        "models['Tuned XGBoost'] = tuned_xgb_model\n",
        "print(\"Tuned XGBoost evaluated on test set.\")\n",
        "print(pd.DataFrame([results['Tuned XGBoost']], index=['Tuned XGBoost']).round(3))\n",
        "\n",
        "# --- Handling Class Imbalance with SMOTE  (Random Forest) ---\n",
        "print(\"\\n--- Handling Class Imbalance with SMOTE  (Random Forest) ---\")\n",
        "\n",
        "pipeline_smote_rf = ImbPipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('classifier', RandomForestClassifier(random_state=42, n_estimators=100))\n",
        "])\n",
        "\n",
        "print(\"Training Random Forest with SMOTE ...\")\n",
        "pipeline_smote_rf.fit(X_train_processed, y_train)\n",
        "y_pred_smote_rf = pipeline_smote_rf.predict(X_test_processed)\n",
        "y_prob_smote_rf = pipeline_smote_rf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "smote_accuracy_rf = accuracy_score(y_test, y_pred_smote_rf)\n",
        "smote_precision_rf = precision_score(y_test, y_pred_smote_rf, zero_division=0)\n",
        "smote_recall_rf = recall_score(y_test, y_pred_smote_rf, zero_division=0)\n",
        "smote_f1_rf = f1_score(y_test, y_pred_smote_rf, zero_division=0)\n",
        "smote_auc_rf = roc_auc_score(y_test, y_prob_smote_rf)\n",
        "\n",
        "results['RF + SMOTE'] = {\n",
        "    'Accuracy': smote_accuracy_rf, 'Precision': smote_precision_rf, 'Recall': smote_recall_rf,\n",
        "    'F1-Score': smote_f1_rf, 'AUC-ROC': smote_auc_rf\n",
        "}\n",
        "models['RF + SMOTE'] = pipeline_smote_rf\n",
        "print(\"Random Forest with SMOTE evaluated on test set.\")\n",
        "print(pd.DataFrame([results['RF + SMOTE']], index=['RF + SMOTE']).round(3))\n",
        "\n",
        "\n",
        "\n",
        "# --- Deep Learning Model with Keras ---\n",
        "print(\"\\n--- Deep Learning Model with Keras ---\")\n",
        "\n",
        "def create_keras_model(input_dim):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
        "        Dropout(0.3),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
        "    return model\n",
        "\n",
        "input_dim = X_train_processed.shape[1]\n",
        "keras_model = create_keras_model(input_dim)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "print(\"Training Keras Deep Learning Model. This will show training progress...\")\n",
        "history = keras_model.fit(\n",
        "    X_train_processed, y_train,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=0\n",
        ")\n",
        "print(\"Keras Deep Learning Model training complete.\")\n",
        "\n",
        "loss, accuracy_keras, auc_keras = keras_model.evaluate(X_test_processed, y_test, verbose=0)\n",
        "y_prob_keras = keras_model.predict(X_test_processed).flatten()\n",
        "y_pred_keras = (y_prob_keras > 0.5).astype(int)\n",
        "\n",
        "precision_keras = precision_score(y_test, y_pred_keras, zero_division=0)\n",
        "recall_keras = recall_score(y_test, y_pred_keras, zero_division=0)\n",
        "f1_keras = f1_score(y_test, y_pred_keras, zero_division=0)\n",
        "\n",
        "results['Deep Learning (Keras)'] = {\n",
        "    'Accuracy': accuracy_keras, 'Precision': precision_keras, 'Recall': recall_keras,\n",
        "    'F1-Score': f1_keras, 'AUC-ROC': auc_keras\n",
        "}\n",
        "models['Deep Learning (Keras)'] = keras_model\n",
        "print(\"Deep Learning (Keras) evaluated on test set.\")\n",
        "print(pd.DataFrame([results['Deep Learning (Keras)']], index=['Deep Learning (Keras)']).round(3))\n",
        "\n",
        "# --- Stacking Classifier ---\n",
        "print(\"\\n--- Stacking Classifier ---\")\n",
        "\n",
        "estimators = [\n",
        "    ('lr', models['Logistic Regression']),\n",
        "    ('tuned_rf', models['Tuned Random Forest']),\n",
        "    ('tuned_xgb', models['Tuned XGBoost']),\n",
        "    ('mlp', models['Neural Network (MLP)'])\n",
        "]\n",
        "\n",
        "stk_meta_classifier = LogisticRegression(random_state=42, solver='liblinear')\n",
        "\n",
        "stacking_clf = StackingClassifier(\n",
        "    estimators=estimators,\n",
        "    final_estimator=stk_meta_classifier,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    passthrough=True\n",
        ")\n",
        "\n",
        "print(\"Training Stacking Classifier. ..\")\n",
        "stacking_clf.fit(X_train_processed, y_train)\n",
        "y_pred_stk = stacking_clf.predict(X_test_processed)\n",
        "y_prob_stk = stacking_clf.predict_proba(X_test_processed)[:, 1]\n",
        "\n",
        "accuracy_stk = accuracy_score(y_test, y_pred_stk)\n",
        "precision_stk = precision_score(y_test, y_pred_stk, zero_division=0)\n",
        "recall_stk = recall_score(y_test, y_pred_stk, zero_division=0)\n",
        "f1_stk = f1_score(y_test, y_pred_stk, zero_division=0)\n",
        "auc_stk = roc_auc_score(y_test, y_prob_stk)\n",
        "\n",
        "results['Stacking Classifier'] = {\n",
        "    'Accuracy': accuracy_stk, 'Precision': precision_stk, 'Recall': recall_stk,\n",
        "    'F1-Score': f1_stk, 'AUC-ROC': auc_stk\n",
        "}\n",
        "models['Stacking Classifier'] = stacking_clf\n",
        "print(\"Stacking Classifier trained and evaluated.\")\n",
        "print(pd.DataFrame([results['Stacking Classifier']], index=['Stacking Classifier']).round(3))\n"
      ],
      "metadata": {
        "id": "qZht2iNbeurZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 16: Display All Model Results ---\n",
        "print(\"\\n--- Step 16: Final Model Performance Benchmarking  ---\")\n",
        "results_df_final = pd.DataFrame(results).T\n",
        "print(results_df_final.round(3))\n",
        "\n",
        "# --- Step 17: Visualize ROC Curves  ---\n",
        "print(\"\\n--- Step 17: Visualizing ROC Curves ---\")\n",
        "plt.figure(figsize=(18, 12))\n",
        "lw = 2\n",
        "prob_maps = {\n",
        "    'Logistic Regression': y_prob_lr,\n",
        "    'Random Forest': y_prob_rf,\n",
        "    'XGBoost': y_prob_xgb,\n",
        "    'SVM': y_prob_svm,\n",
        "    'Neural Network (MLP)': y_prob_mlp,\n",
        "    'KNN': y_prob_knn,\n",
        "    'Naive Bayes': y_prob_gnb,\n",
        "    'Voting Classifier': y_prob_voting,\n",
        "    'Tuned Random Forest': y_prob_tuned_rf,\n",
        "    'Tuned XGBoost': y_prob_tuned_xgb,\n",
        "    'RF + SMOTE': y_prob_smote_rf,\n",
        "    'Deep Learning (Keras)': y_prob_keras,\n",
        "    'Stacking Classifier': y_prob_stk\n",
        "}\n",
        "\n",
        "for name, y_prob in prob_maps.items():\n",
        "    if y_prob is not None:\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "        auc_score = results[name]['AUC-ROC']\n",
        "        plt.plot(fpr, tpr, lw=lw, label=f'{name} (AUC = {auc_score:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Pain Prediction')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show() # Display the plot directly\n",
        "print(\"ROC Curve displayed above.\")\n",
        "\n",
        "# --- Step 18: Generate and Display Confusion Matrices  ---\n",
        "print(\"\\n--- Step 18: Generating Confusion Matrices ---\")\n",
        "labels = np.unique(y_test)\n",
        "\n",
        "num_models_to_plot = len(results)\n",
        "cols = 4\n",
        "rows = (num_models_to_plot + cols - 1) // cols\n",
        "\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(5 * cols, 5 * rows))\n",
        "axes = axes.flatten()\n",
        "\n",
        "pred_maps = {\n",
        "    'Logistic Regression': y_pred_lr,\n",
        "    'Random Forest': y_pred_rf,\n",
        "    'XGBoost': y_pred_xgb,\n",
        "    'SVM': y_pred_svm,\n",
        "    'Neural Network (MLP)': y_pred_mlp,\n",
        "    'KNN': y_pred_knn,\n",
        "    'Naive Bayes': y_pred_gnb,\n",
        "    'Voting Classifier': y_pred_voting,\n",
        "    'Tuned Random Forest': y_pred_tuned_rf,\n",
        "    'Tuned XGBoost': y_pred_tuned_xgb,\n",
        "    'RF + SMOTE': y_pred_smote_rf,\n",
        "    'Deep Learning (Keras)': y_pred_keras,\n",
        "    'Stacking Classifier': y_pred_stk\n",
        "}\n",
        "\n",
        "for i, (name, y_pred) in enumerate(pred_maps.items()):\n",
        "    if y_pred is not None and i < len(axes):\n",
        "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
        "        disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "        disp.plot(cmap=plt.cm.Blues, ax=axes[i], values_format='d')\n",
        "        axes[i].set_title(f'CM: {name}')\n",
        "\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show() # Display the plot directly\n",
        "\n"
      ],
      "metadata": {
        "id": "a9EqV_TGfaao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 19: Basic Model Interpretability ---\n",
        "print(\"\\n--- Step 19: Basic Model Interpretability  ---\")\n",
        "\n",
        "if 'processed_feature_names' not in locals() or not processed_feature_names:\n",
        "    print(\"Feature names not \")\n",
        "else:\n",
        "    print(\"\\nLogistic Regression Coefficients (Top 10 by Absolute Magnitude):\")\n",
        "    lr_coefficients = pd.DataFrame({'Feature': processed_feature_names, 'Coefficient': log_reg_model.coef_[0]})\n",
        "    lr_coefficients['Absolute_Coefficient'] = np.abs(lr_coefficients['Coefficient'])\n",
        "    lr_coefficients = lr_coefficients.sort_values(by='Absolute_Coefficient', ascending=False)\n",
        "    print(lr_coefficients.head(10))\n",
        "\n",
        "    print(\"\\nRandom Forest Feature Importance (Top 10 - using original RF):\")\n",
        "    rf_feature_importances = pd.DataFrame({'Feature': processed_feature_names, 'Importance': rf_model.feature_importances_})\n",
        "    rf_feature_importances = rf_feature_importances.sort_values(by='Importance', ascending=False)\n",
        "    print(rf_feature_importances.head(10))\n",
        "\n",
        "    print(\"\\nXGBoost Feature Importance (Top 10):\")\n",
        "    xgb_feature_importances = pd.DataFrame({'Feature': processed_feature_names, 'Importance': xgb_model.feature_importances_})\n",
        "    xgb_feature_importances = xgb_feature_importances.sort_values(by='Importance', ascending=False)\n",
        "    print(xgb_feature_importances.head(10))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# --- Step 20: Model Interpretability with SHAP (for Tuned XGBoost)  ---\n",
        "print(\"\\n--- Step 20:  Model Interpretability with SHAP (Tuned XGBoost) ---\")\n",
        "\n",
        "if not isinstance(processed_feature_names, list):\n",
        "    processed_feature_names = [f'feature_{i}' for i in range(X_train_processed.shape[1])]\n",
        "\n",
        "X_test_processed_df = pd.DataFrame(X_test_processed, columns=processed_feature_names)\n",
        "\n",
        "try:\n",
        "    explainer = shap.TreeExplainer(models['Tuned XGBoost'])\n",
        "    shap_values = explainer.shap_values(X_test_processed_df)\n",
        "\n",
        "    print(\"\\n SHAP Summary Plot (Global Feature Importance - Bar Plot)...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values, X_test_processed_df, plot_type=\"bar\", show=False)\n",
        "    plt.title('SHAP Feature Importance for Tuned XGBoost ')\n",
        "    plt.tight_layout()\n",
        "    plt.show() # Display plot\n",
        "    print(\"SHAP Summary Bar Plot displayed above.\")\n",
        "\n",
        "    print(\"\\nGenerating SHAP Summary Plot (Beeswarm Plot)...\")\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    shap.summary_plot(shap_values, X_test_processed_df, show=False) # Beeswarm plot\n",
        "    plt.title('SHAP Summary Plot (Beeswarm) for Tuned XGBoost ')\n",
        "    plt.tight_layout()\n",
        "    plt.show() #  plot\n",
        "\n",
        "    if 'age' in processed_feature_names:\n",
        "        print(\"\\nGenerating SHAP Dependence Plot for 'age'...\")\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        shap.dependence_plot(\"age\", shap_values, X_test_processed_df, show=False)\n",
        "        plt.title('SHAP Dependence Plot for Age ')\n",
        "        plt.tight_layout()\n",
        "        plt.show() # plot\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during SHAP analysis: {e}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wfE9qgtqfxHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.calibration import CalibrationDisplay\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# --- Step 22: Feature Importances for All Models ---\n",
        "print(\"\\n--- Step 22: Feature Importances for All Models ---\")\n",
        "\n",
        "feature_importance_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    try:\n",
        "        if hasattr(model, \"feature_importances_\"):\n",
        "            importance_vals = model.feature_importances_\n",
        "        elif hasattr(model, \"coef_\"):\n",
        "            importance_vals = np.abs(model.coef_[0])  # Logistic Regression\n",
        "        else:\n",
        "            # permutation importance\n",
        "            perm_result = permutation_importance(\n",
        "                model, X_test_processed, y_test,\n",
        "                n_repeats=10, random_state=42, n_jobs=-1\n",
        "            )\n",
        "            importance_vals = perm_result.importances_mean\n",
        "\n",
        "        feature_importance_results[name] = pd.DataFrame({\n",
        "            \"Feature\": processed_feature_names,\n",
        "            f\"Importance_{name}\": importance_vals\n",
        "        }).sort_values(by=f\"Importance_{name}\", ascending=False)\n",
        "\n",
        "        print(f\"\\nTop 10 Features for {name}:\")\n",
        "        print(feature_importance_results[name].head(10))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping feature importance for {name}: {e}\")\n",
        "\n",
        "# --- Step 23: Combined Feature Importance Plot (Grouped Bars) ---\n",
        "print(\"\\n--- Step 23: Combined Feature Importance Plot ---\")\n",
        "\n",
        "# all importance tables\n",
        "merged_importances = feature_importance_results[list(feature_importance_results.keys())[0]][[\"Feature\"]]\n",
        "\n",
        "for name, df_imp in feature_importance_results.items():\n",
        "    merged_importances = merged_importances.merge(df_imp, on=\"Feature\", how=\"left\")\n",
        "\n",
        "# --- NEW: Scale all importance values per model to [0,1] ---\n",
        "scaler = MinMaxScaler()\n",
        "for col in merged_importances.columns:\n",
        "    if col != \"Feature\":\n",
        "        merged_importances[col] = scaler.fit_transform(merged_importances[[col]])\n",
        "\n",
        "# Melt for plotting\n",
        "merged_melted = pd.melt(\n",
        "    merged_importances,\n",
        "    id_vars=\"Feature\",\n",
        "    var_name=\"Model\",\n",
        "    value_name=\"Importance\"\n",
        ")\n",
        "\n",
        "plt.figure(figsize=(18, 8))\n",
        "sns.barplot(data=merged_melted, x=\"Feature\", y=\"Importance\", hue=\"Model\")\n",
        "plt.title(\"Top Normalized Features across Models\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "from sklearn.calibration import CalibrationDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"\\n--- Step 24: Calibration Curves ---\")\n",
        "\n",
        "# Define 12 distinct colors\n",
        "colors = [\n",
        "    \"#1f77b4\" ,\"#7f7788\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\",\n",
        "    \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\", \"#aec7e8\", \"#fcbb70\"\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for i, (name, y_prob) in enumerate(prob_maps.items()):\n",
        "    color = colors[i % len(colors)]  # cycle colors if more than 12\n",
        "    try:\n",
        "        CalibrationDisplay.from_predictions(\n",
        "            y_test, y_prob, n_bins=10, strategy='uniform',\n",
        "            name=name, ax=plt.gca(), color=color\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping calibration for {name}: {e}\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly Calibrated\")\n",
        "plt.title(\"Calibration Curves for All Models\")\n",
        "plt.xlabel(\"Mean Predicted Probability\")\n",
        "plt.ylabel(\"Fraction of Positives\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6DmR_hPgf64Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}